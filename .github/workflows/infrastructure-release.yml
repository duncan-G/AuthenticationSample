name: 'Infrastructure Release'

on:
  # Manual trigger with choice of action
  workflow_dispatch:
    inputs:
      action:
        description: 'Infrastructure Action'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - deploy
          - destroy
      environment:
        description: 'Target Environment'
        required: true
        default: 'terraform-staging'
        type: choice
        options:
          - terraform-staging
          - terraform-production

  # Automatic plan on pull requests
  pull_request:
    branches: [ main ]
    paths: [ 'Infrastructure/terraform/modules/**' ]

  # Only plan on main branch pushes (no auto-deploy)
  push:
    branches: [ main ]
    paths: [ 'Infrastructure/terraform/modules/**' ]

env:
  AWS_DEFAULT_REGION: ${{ vars.AWS_DEFAULT_REGION || 'us-west-1' }}
  TERRAFORM_VERSION: "1.12.2"
  TF_VAR_app_name: ${{ secrets.TF_APP_NAME }}
  TF_VAR_region: ${{ vars.AWS_DEFAULT_REGION || 'us-west-1' }}
  TF_VAR_github_repository: ${{ secrets.GITHUB_REPOSITORY }}
  TF_VAR_deployment_bucket: ${{ secrets.DEPLOYMENT_BUCKET }}
  TF_VAR_staging_environment: ${{ vars.STAGING_ENVIRONMENT || 'codedeploy-staging' }}
  TF_VAR_production_environment: ${{ vars.PRODUCTION_ENVIRONMENT || 'codedeploy-production' }}
  
permissions:
  contents: read
  pull-requests: write
  id-token: write
  issues: write

jobs:
  terraform-plan:
    name: 'Terraform Plan'
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'terraform-staging' }}
    
    # Only allow one terraform run at a time per environment
    concurrency:
      group: terraform-${{ github.event.inputs.environment || 'terraform-staging' }}
      cancel-in-progress: false

    defaults:
      run:
        shell: bash
        working-directory: ./Infrastructure/terraform/modules

    outputs:
      plan-exitcode: ${{ steps.plan.outputs.exitcode }}
      plan-output: ${{ steps.plan.outputs.stdout }}
      has-changes: ${{ steps.plan.outputs.exitcode == 2 }}

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}
        terraform_wrapper: false

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with: 
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-terraform
        role-session-name: GitHubActions-Terraform-${{ github.run_id }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}

    - name: Terraform Format Check
      id: fmt
      run: |
        if ! terraform fmt -check -recursive; then
          echo "‚ùå Terraform files are not properly formatted"
          echo "Run 'terraform fmt -recursive' to fix formatting issues"
          exit 1
        fi
        echo "‚úÖ All Terraform files are properly formatted"

    - name: Terraform Init
      id: init
      run: |
        echo "üîß Initializing Terraform..."
        
        # Use environment variable for S3 bucket name
        TF_STATE_BUCKET="${{ secrets.TF_STATE_BUCKET }}"
        
        if [ -z "$TF_STATE_BUCKET" ]; then
          echo "‚ùå Error: TF_STATE_BUCKET environment variable is not set"
          exit 1
        fi

        TF_WORKSPACE_PREFIX="${{ secrets.TF_APP_NAME }}"
        
        # Initialize with partial backend configuration
        terraform init \
          -backend-config="bucket=$TF_STATE_BUCKET" \
          -backend-config="region=${{ env.AWS_DEFAULT_REGION }}" \
          -backend-config="workspace_key_prefix=$TF_WORKSPACE_PREFIX" \
          -no-color
        
        # Verify backend configuration
        if ! terraform state list > /dev/null 2>&1; then
          echo "‚ö†Ô∏è  Warning: Unable to access Terraform state"
        else
          echo "‚úÖ Terraform state backend is accessible"
        fi

    - name: Terraform Workspace
      id: workspace
      run: |
        WORKSPACE="${{ github.event.inputs.environment || 'terraform-staging' }}"
        echo "üèóÔ∏è  Setting up workspace: $WORKSPACE"
        
        # Use -or-create flag to automatically create workspace if it doesn't exist
        terraform workspace select -or-create "$WORKSPACE"
        
        echo "Current workspace: $(terraform workspace show)"

    - name: Terraform Validate
      id: validate
      run: |
        echo "‚úÖ Validating Terraform configuration..."
        terraform validate -no-color

    - name: Terraform Plan
      id: plan
      run: |
        echo "üìã Running Terraform plan..."
        
        # Set plan file name based on action
        PLAN_FILE="tfplan-${{ github.event.inputs.action || 'plan' }}"
        
        # Temporarily disable exit-on-error to capture Terraform's exit codes
        # Terraform returns exit code 2 for successful plans with changes (not an error!)
        set +e
        
        # Determine plan type
        case "${{ github.event.inputs.action }}" in
          "destroy")
            echo "üî• Planning infrastructure destruction..."
            terraform plan -destroy -no-color -input=false -out="$PLAN_FILE" -detailed-exitcode \
              -var="github_repository=${{ secrets.GITHUB_REPOSITORY }}" \
              -var="deployment_bucket=${{ secrets.DEPLOYMENT_BUCKET }}" \
              -var="staging_environment=${{ vars.STAGING_ENVIRONMENT || 'codedeploy-staging' }}" \
              -var="production_environment=${{ vars.PRODUCTION_ENVIRONMENT || 'codedeploy-production' }}"
            PLAN_EXIT_CODE=$?
            ;;
          *)
            echo "üöÄ Planning infrastructure deployment..."
            terraform plan -no-color -input=false -out="$PLAN_FILE" -detailed-exitcode \
              -var="github_repository=${{ secrets.GITHUB_REPOSITORY }}" \
              -var="deployment_bucket=${{ secrets.DEPLOYMENT_BUCKET }}" \
              -var="staging_environment=${{ vars.STAGING_ENVIRONMENT || 'codedeploy-staging' }}" \
              -var="production_environment=${{ vars.PRODUCTION_ENVIRONMENT || 'codedeploy-production' }}"
            PLAN_EXIT_CODE=$?
            ;;
        esac
        
        # Restore exit-on-error behavior
        set -e
        
        # Save exit code and plan file for other steps
        echo "exitcode=$PLAN_EXIT_CODE" >> $GITHUB_OUTPUT
        echo "plan-file=$PLAN_FILE" >> $GITHUB_OUTPUT
        
        # Handle Terraform exit codes properly
        if [ $PLAN_EXIT_CODE -eq 1 ]; then
          echo "‚ùå Terraform plan failed with errors"
          exit 1
        elif [ $PLAN_EXIT_CODE -eq 2 ]; then
          echo "üìã Terraform plan completed successfully - changes detected"
        elif [ $PLAN_EXIT_CODE -eq 0 ]; then
          echo "‚úÖ Terraform plan completed successfully - no changes needed"
        else
          echo "‚ùì Unexpected exit code: $PLAN_EXIT_CODE"
          exit 1
        fi

    - name: Upload Plan File
      if: steps.plan.outputs.exitcode == 2
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan-${{ github.event.inputs.environment || 'terraform-staging' }}-${{ github.run_id }}
        path: Infrastructure/terraform/modules/tfplan-*
        retention-days: 5

    - name: Update Pull Request
      uses: actions/github-script@v7
      if: github.event_name == 'pull_request'
      env:
        PLAN: ${{ steps.plan.outputs.stdout }}
        FMT: ${{ steps.fmt.outcome }}
        INIT: ${{ steps.init.outcome }}
        VALIDATE: ${{ steps.validate.outcome }}
        PLAN_EXITCODE: ${{ steps.plan.outputs.exitcode }}
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const { PLAN, FMT, INIT, VALIDATE, PLAN_EXITCODE } = process.env;
          const hasChanges = PLAN_EXITCODE === '2';
          const hasError = PLAN_EXITCODE === '1';
          
          const planStatus = hasError ? '‚ùå Error' : hasChanges ? 'üìã Has Changes' : '‚úÖ No Changes';
          
          const output = `## Terraform Plan Results
          
          | Step | Status |
          |------|--------|
          | üñå Format | \`${FMT}\` |
          | ‚öôÔ∏è Init | \`${INIT}\` |
          | ü§ñ Validate | \`${VALIDATE}\` |
          | üìã Plan | ${planStatus} |
          
          ${hasChanges || hasError ? `
          <details><summary>üìã Show Plan Output</summary>
          
          \`\`\`hcl
          ${PLAN}
          \`\`\`
          
          </details>
          ` : ''}
          
          ${hasError ? '‚ùå **Plan failed!** Please review the errors above.' : ''}
          ${hasChanges ? '‚ö†Ô∏è **This PR will make infrastructure changes.** Review carefully before merging.' : ''}
          
          *Triggered by: @${{ github.actor }} ‚Ä¢ Event: \`${{ github.event_name }}\`*`;

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: output
          });

    - name: Plan Summary
      if: always()
      run: |
        echo "## Terraform Plan Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Environment**: ${{ github.event.inputs.environment || 'terraform-staging' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Action**: ${{ github.event.inputs.action || 'plan' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Workspace**: $(terraform workspace show)" >> $GITHUB_STEP_SUMMARY
        
        case "${{ steps.plan.outputs.exitcode }}" in
          "0") echo "- **Result**: ‚úÖ No changes needed" >> $GITHUB_STEP_SUMMARY ;;
          "1") echo "- **Result**: ‚ùå Plan failed" >> $GITHUB_STEP_SUMMARY ;;
          "2") echo "- **Result**: üìã Changes detected" >> $GITHUB_STEP_SUMMARY ;;
        esac

  terraform-apply:
    name: 'Terraform Apply'
    runs-on: ubuntu-latest
    if: |
      (github.event.inputs.action == 'deploy' || github.event.inputs.action == 'destroy') &&
      github.event_name == 'workflow_dispatch' &&
      needs.terraform-plan.outputs.has-changes == 'true'
    needs: terraform-plan
    environment: ${{ github.event.inputs.environment }}
    
    concurrency:
      group: terraform-apply-${{ github.event.inputs.environment }}
      cancel-in-progress: false

    defaults:
      run:
        shell: bash
        working-directory: ./Infrastructure/terraform/modules

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}
        terraform_wrapper: false

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-terraform
        role-session-name: GitHubActions-Terraform-Apply-${{ github.run_id }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}

    - name: Terraform Init
      run: |
        TF_STATE_BUCKET="${{ secrets.TF_STATE_BUCKET }}"
        
        if [ -z "$TF_STATE_BUCKET" ]; then
          echo "‚ùå Error: TF_STATE_BUCKET environment variable is not set"
          exit 1
        fi

        TF_WORKSPACE_PREFIX="${{ secrets.TF_APP_NAME }}"
        
        # Initialize with partial backend configuration
        terraform init \
          -backend-config="bucket=$TF_STATE_BUCKET" \
          -backend-config="region=${{ env.AWS_DEFAULT_REGION }}" \
          -backend-config="workspace_key_prefix=$TF_WORKSPACE_PREFIX" \
          -no-color
        
        # Verify backend configuration
        if ! terraform state list > /dev/null 2>&1; then
          echo "‚ö†Ô∏è  Warning: Unable to access Terraform state"
        else
          echo "‚úÖ Terraform state backend is accessible"
        fi

    - name: Setup Workspace
      run: |
        WORKSPACE="${{ github.event.inputs.environment }}"
        terraform workspace select -or-create "$WORKSPACE"
        echo "Current workspace: $(terraform workspace show)"

    - name: Download Plan File
      uses: actions/download-artifact@v4
      with:
        name: terraform-plan-${{ github.event.inputs.environment }}-${{ github.run_id }}
        path: Infrastructure/terraform/modules/

    - name: Terraform Apply
      id: apply
      run: |
        echo "üöÄ Applying Terraform changes..."
        terraform apply -no-color -input=false -auto-approve "${{ steps.plan.outputs.plan-file }}"
        
        if [ $? -eq 0 ]; then
          echo "‚úÖ Terraform apply completed successfully"
          echo "success=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Terraform apply failed"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: Terraform Output
      if: github.event.inputs.action == 'deploy'
      run: |
        echo "## Infrastructure Outputs" >> $GITHUB_STEP_SUMMARY
        terraform output -no-color | while IFS= read -r line; do
          echo "- $line" >> $GITHUB_STEP_SUMMARY
        done

    - name: Apply Summary
      if: always()
      run: |
        echo "## Terraform Apply Results" >> $GITHUB_STEP_SUMMARY
        echo "- **Environment**: ${{ github.event.inputs.environment }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Action**: ${{ github.event.inputs.action }}" >> $GITHUB_STEP_SUMMARY
        
        case "${{ steps.apply.outputs.exitcode }}" in
          "0") echo "- **Status**: ‚úÖ Success" >> $GITHUB_STEP_SUMMARY ;;
          *) echo "- **Status**: ‚ùå Failed" >> $GITHUB_STEP_SUMMARY ;;
        esac
        
        echo "- **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY

  verify-docker-setup:
    name: 'Verify Docker Manager Setup'
    runs-on: ubuntu-latest
    if: |
      github.event.inputs.action == 'deploy' &&
      github.event_name == 'workflow_dispatch' &&
      needs.terraform-apply.outputs.success == 'true'
    needs: terraform-apply
    environment: ${{ github.event.inputs.environment }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-terraform
        role-session-name: GitHubActions-VerifySetup-${{ github.run_id }}
        aws-region: ${{ env.AWS_DEFAULT_REGION }}

    - name: Get Instance ID
      id: get-instance
      run: |
        # Get the private instance ID from Terraform output
        cd Infrastructure/terraform/modules
        
        # Initialize Terraform to get outputs
        terraform init \
          -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
          -backend-config="region=${{ env.AWS_DEFAULT_REGION }}" \
          -backend-config="workspace_key_prefix=${{ secrets.TF_APP_NAME }}" \
          -no-color
        
        terraform workspace select "${{ github.event.inputs.environment }}"
        
        # Get instance ID from Terraform output
        INSTANCE_ID=$(terraform output -raw private_instance_ip 2>/dev/null || echo "")
        if [ -z "$INSTANCE_ID" ]; then
          echo "‚ùå Could not get instance ID from Terraform output"
          exit 1
        fi
        
        echo "instance-id=$INSTANCE_ID" >> $GITHUB_OUTPUT
        echo "üîç Checking Docker manager setup on instance: $INSTANCE_ID"

    - name: Check Docker Manager Setup Status
      run: |
        INSTANCE_ID="${{ steps.get-instance.outputs.instance-id }}"
        
        echo "‚è≥ Waiting for Docker manager setup to complete..."
        
        # Wait up to 10 minutes for setup to complete
        for i in {1..60}; do
          echo "Attempt $i/60: Checking setup status..."
          
          # Check if status file exists and read its content
          STATUS=$(aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=["cat /tmp/docker-manager-setup.status 2>/dev/null || echo \"NOT_FOUND\""]' \
            --query 'Command.CommandId' \
            --output text 2>/dev/null || echo "")
          
          if [ -n "$STATUS" ]; then
            # Wait a moment for command to complete
            sleep 10
            
            # Get command output
            RESULT=$(aws ssm get-command-invocation \
              --command-id "$STATUS" \
              --instance-id "$INSTANCE_ID" \
              --query 'StandardOutputContent' \
              --output text 2>/dev/null || echo "")
            
            if [[ "$RESULT" == *"SUCCESS"* ]]; then
              echo "‚úÖ Docker manager setup completed successfully!"
              echo "Setup Status: $RESULT"
              break
            elif [[ "$RESULT" == *"FAILED"* ]]; then
              echo "‚ùå Docker manager setup failed!"
              echo "Failure Details: $RESULT"
              
              # Get the setup log for more details
              echo "üìã Retrieving setup logs..."
              aws ssm send-command \
                --instance-ids "$INSTANCE_ID" \
                --document-name "AWS-RunShellScript" \
                --parameters 'commands=["tail -50 /var/log/docker-manager-setup.log 2>/dev/null || echo \"No log file found\""]' \
                --query 'Command.CommandId' \
                --output text > /dev/null
              
              exit 1
            fi
          fi
          
          echo "Setup not complete yet, waiting 10 seconds..."
          sleep 10
        done
        
        if [ $i -eq 60 ]; then
          echo "‚è∞ Timeout: Docker manager setup did not complete within 10 minutes"
          echo "üìã Retrieving current status and logs..."
          
          # Get current status
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=["cat /tmp/docker-manager-setup.status 2>/dev/null || echo \"Status file not found\"; echo \"---\"; tail -20 /var/log/docker-manager-setup.log 2>/dev/null || echo \"Log file not found\""]' \
            --query 'Command.CommandId' \
            --output text > /dev/null
          
          exit 1
        fi

    - name: Verify Docker Swarm Status
      run: |
        INSTANCE_ID="${{ steps.get-instance.outputs.instance-id }}"
        
        echo "üîç Verifying Docker Swarm status..."
        
        # Check if Docker Swarm is active
        SWARM_STATUS=$(aws ssm send-command \
          --instance-ids "$INSTANCE_ID" \
          --document-name "AWS-RunShellScript" \
          --parameters 'commands=["docker info --format \"{{.Swarm.LocalNodeState}}\" 2>/dev/null || echo \"Docker not available\""]' \
          --query 'Command.CommandId' \
          --output text)
        
        sleep 5
        
        RESULT=$(aws ssm get-command-invocation \
          --command-id "$SWARM_STATUS" \
          --instance-id "$INSTANCE_ID" \
          --query 'StandardOutputContent' \
          --output text)
        
        if [[ "$RESULT" == "active" ]]; then
          echo "‚úÖ Docker Swarm is active and running"
        else
          echo "‚ùå Docker Swarm is not active. Status: $RESULT"
          exit 1
        fi
        
        # Check if overlay network exists
        NETWORK_STATUS=$(aws ssm send-command \
          --instance-ids "$INSTANCE_ID" \
          --document-name "AWS-RunShellScript" \
          --parameters 'commands=["docker network ls --filter name=app-network --format \"{{.Name}}\" 2>/dev/null || echo \"Network not found\""]' \
          --query 'Command.CommandId' \
          --output text)
        
        sleep 5
        
        NETWORK_RESULT=$(aws ssm get-command-invocation \
          --command-id "$NETWORK_STATUS" \
          --instance-id "$INSTANCE_ID" \
          --query 'StandardOutputContent' \
          --output text)
        
        if [[ "$NETWORK_RESULT" == "app-network" ]]; then
          echo "‚úÖ Overlay network 'app-network' exists"
        else
          echo "‚ùå Overlay network 'app-network' not found. Available networks: $NETWORK_RESULT"
          exit 1
        fi 